{"id":"00000000-0000-0000-0000-000000000000","revision":0,"last_node_id":55,"last_link_id":12,"nodes":[{"id":1,"type":"CLIPTextEncode","pos":[2650,1280],"size":[285.6000061035156,130],"flags":{},"order":50,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":1}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[7]}],"title":"CLIP Text Encode (Negative Prompt)","properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"CLIPTextEncode"},"widgets_values":["色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走"],"color":"#322","bgcolor":"#533"},{"id":2,"type":"Note","pos":[1840,1390],"size":[400,88],"flags":{},"order":0,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["Kijai's Clip Vision model can only be loaded by Load WanVideo Clip Encoder Node.\nComfyOrg's Clip Vision model can only be loaded by default Loader."],"color":"#432","bgcolor":"#653"},{"id":4,"type":"WanVideoVRAMManagement","pos":[2040,570],"size":[320,58],"flags":{},"order":1,"mode":0,"inputs":[],"outputs":[{"localized_name":"vram_management_args","name":"vram_management_args","type":"VRAM_MANAGEMENTARGS","links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoVRAMManagement"},"widgets_values":[1],"color":"#223","bgcolor":"#335"},{"id":5,"type":"Note","pos":[1680,100],"size":[220,88],"flags":{},"order":2,"mode":0,"inputs":[],"outputs":[],"title":"Triton","properties":{},"widgets_values":["Wan Video Torch Compile Settings is disconnected by default and will not take effect if you're using fp8 diffusion model and your graphic card is 20xx or 30xx."],"color":"#432","bgcolor":"#653"},{"id":6,"type":"Note","pos":[1680,360],"size":[330,130],"flags":{},"order":3,"mode":0,"inputs":[],"outputs":[],"title":"Block Swap","properties":{},"widgets_values":["like --normalvram | --lowvram argument, BlockSwap adjusts the blocks to swap with RAM based on your VRAM, this is a tradeoff between speed and memory usage. \nMax transformer blocks: 40 for 14B, 30 for 1.3B\n\nDo not to exceed the total VRAM, or it will be much more slower because ComfyUI will start unloading models from VRAM to RAM."],"color":"#432","bgcolor":"#653"},{"id":7,"type":"Note","pos":[1680,540],"size":[330,88],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"title":"VRAM Management","properties":{},"widgets_values":["Alternatively there's option to use VRAM management introduced in DiffSynt-Studios. This is usually slower, but saves even more VRAM compared to BlockSwap"],"color":"#432","bgcolor":"#653"},{"id":8,"type":"Note","pos":[2910,160],"size":[310,88],"flags":{},"order":5,"mode":0,"inputs":[],"outputs":[],"title":"Text Encode","properties":{},"widgets_values":["If you've already loaded the diffusion model to the offload device, you don't need to link model_to_offload, which will reduce some loading time."],"color":"#432","bgcolor":"#653"},{"id":12,"type":"WanVideoVAELoader","pos":[1840,940],"size":[400,82],"flags":{},"order":6,"mode":0,"inputs":[],"outputs":[{"localized_name":"vae","name":"vae","type":"WANVAE","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoVAELoader"},"widgets_values":["WanVideo\\Wan2_1_VAE_fp32.safetensors","fp32"]},{"id":13,"type":"VAELoader","pos":[1840,830],"size":[400,60],"flags":{},"order":7,"mode":0,"inputs":[],"outputs":[{"localized_name":"VAE","name":"VAE","type":"VAE","slot_index":0,"links":[]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"VAELoader","models":[{"name":"wan_2.1_vae.safetensors","url":"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/vae/wan_2.1_vae.safetensors?download=true","directory":"vae"}]},"widgets_values":["WanVideo\\Wan2_1_VAE_fp32.safetensors"]},{"id":14,"type":"CLIPTextEncode","pos":[2650,1140],"size":[285.6000061035156,100],"flags":{},"order":51,"mode":0,"inputs":[{"localized_name":"clip","name":"clip","type":"CLIP","link":5}],"outputs":[{"localized_name":"CONDITIONING","name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[6]}],"title":"CLIP Text Encode (Positive Prompt)","properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"CLIPTextEncode"},"widgets_values":["a monkey robot is smiling"],"color":"#232","bgcolor":"#353"},{"id":17,"type":"LoadWanVideoT5TextEncoder","pos":[2280,830],"size":[460,130],"flags":{},"order":8,"mode":4,"inputs":[],"outputs":[{"localized_name":"wan_t5_model","name":"wan_t5_model","type":"WANTEXTENCODER","slot_index":0,"links":[9]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"LoadWanVideoT5TextEncoder"},"widgets_values":["WanVideo\\Kijai\\umt5-xxl-enc-fp8_e4m3fn.safetensors","bf16","offload_device","disabled"]},{"id":18,"type":"SkipLayerGuidanceSD3","pos":[590,1210],"size":[290,130],"flags":{},"order":9,"mode":2,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":null}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"SkipLayerGuidanceSD3"},"widgets_values":["7, 8, 9",3,0.01,0.15]},{"id":19,"type":"TorchCompileModel","pos":[-100,1050],"size":[310,60],"flags":{},"order":10,"mode":2,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":null}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"TorchCompileModel"},"widgets_values":["inductor"]},{"id":24,"type":"MarkdownNote","pos":[860,1690],"size":[360,510],"flags":{},"order":11,"mode":0,"inputs":[],"outputs":[],"title":"Running Time Comparison (flf2vid)","properties":{},"widgets_values":["HDD & 64G RAM & 3090ti 24G VRAM  \n81 frames at 480x480 with 25 steps  \nSageAtt+TeaCache+SLG+EnhanceAVid  \nwan2.1_i2v_480p_14B_fp8_e4m3fn.safetensors (ComfyOrg)  \n20 blocks swap for Wrapper  \n\n| 1st Run  | Native | Wrapper |\n|----------|--------|---------|\n| Loading  | 760s   | 770s    |\n| Sampling | 420s   | 365s    |\n| Decoding | 10s    | 15s     |\n| Total    | 1190s  | 1150s   |\n\n| 2nd Run  | Native | Wrapper |\n|----------|--------|---------|\n| Loading  | 0s     | 5s      |\n| Sampling | 420s   | 365s    |\n| Decoding | 5s     | 10s     |\n| Total    | 425s   | 380s    |\n\n (sdpa attention in Wrapper workflow needs to reload the diffusion model)  \n| Speedup(without Triton)          | Native | Wrapper    |\n|----------------------------------|--------|------------|\n| SageAtt+TeaCache+SLG+EnhanceAVid | 425s   | 380s       |\n| SageAtt+TeaCache+SLG             | 310s   | 365s       |\n| SageAtt+TeaCache                 | 320s   | 370s       |\n| SageAtt                          | 524s   | 585s       |\n| -                                | 755s   | 825s(sdpa) |"],"color":"#432","bgcolor":"#653"},{"id":25,"type":"MarkdownNote","pos":[490,1690],"size":[360,510],"flags":{},"order":12,"mode":0,"inputs":[],"outputs":[],"title":"Running Time Comparison (img2vid)","properties":{},"widgets_values":["HDD & 64G RAM & 3090ti 24G VRAM  \n81 frames at 480x480 with 25 steps  \nSageAtt+TeaCache+SLG+EnhanceAVid  \nwan2.1_i2v_480p_14B_fp8_e4m3fn.safetensors (ComfyOrg)  \n20 blocks swap for Wrapper  \n\n| 1st Run  | Native | Wrapper |\n|----------|--------|---------|\n| Loading  | 760s   | 770s    |\n| Sampling | 400s   | 345s    |\n| Decoding | 10s    | 15s     |\n| Total    | 1170s  | 1130s   |\n\n| 2nd Run  | Native | Wrapper |\n|----------|--------|---------|\n| Loading  | 0s     | 5s      |\n| Sampling | 400s   | 345s    |\n| Decoding | 5s     | 10s     |\n| Total    | 405s   | 360s    |\n\n (sdpa attention in Wrapper workflow needs to reload the diffusion model)  \n| Speedup(without Triton)          | Native | Wrapper    |\n|----------------------------------|--------|------------|\n| SageAtt+TeaCache+SLG+EnhanceAVid | 405s   | 360s       |\n| SageAtt+TeaCache+SLG             | 295s   | 345s       |\n| SageAtt+TeaCache                 | 305s   | 355s       |\n| SageAtt                          | 500s   | 560s       |\n| -                                | 720s   | 790s(sdpa) |"],"color":"#432","bgcolor":"#653"},{"id":30,"type":"WanVideoBlockSwap","pos":[2040,360],"size":[320,154],"flags":{},"order":13,"mode":0,"inputs":[],"outputs":[{"localized_name":"block_swap_args","name":"block_swap_args","type":"BLOCKSWAPARGS","slot_index":0,"links":[3]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoBlockSwap"},"widgets_values":[20,false,false,true,0],"color":"#223","bgcolor":"#335"},{"id":31,"type":"Note","pos":[770,500],"size":[230,88],"flags":{},"order":14,"mode":0,"inputs":[],"outputs":[],"title":"Triton error","properties":{},"widgets_values":["type fp8e4nv (fp8 scaled | fp8_e4m3fn | fp8_e5m2) is not supported in CUDA arch < 89 (rtx 20xx or 30xx).\nThe supported fp8 dtypes are ('fp8e4b15', 'fp8e5')?"],"color":"#432","bgcolor":"#653"},{"id":32,"type":"SkipLayerGuidanceDiT","pos":[590,980],"size":[290,180],"flags":{},"order":15,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":null}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"SkipLayerGuidanceDiT"},"widgets_values":["7, 8, 9","7, 8, 9",3,0.01,0.15,0]},{"id":38,"type":"CLIPLoader","pos":[2280,1140],"size":[320,106],"flags":{},"order":16,"mode":0,"inputs":[],"outputs":[{"localized_name":"CLIP","name":"CLIP","type":"CLIP","slot_index":0,"links":[1,5]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"CLIPLoader","models":[{"name":"umt5_xxl_fp8_e4m3fn_scaled.safetensors","url":"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/text_encoders/umt5_xxl_fp8_e4m3fn_scaled.safetensors?download=true","directory":"text_encoders"}]},"widgets_values":["WanVideo\\ComfyOrg\\umt5_xxl_fp8_e4m3fn_scaled.safetensors","wan","default"]},{"id":39,"type":"UNETLoader","pos":[2280,1510],"size":[450,82],"flags":{},"order":17,"mode":0,"inputs":[],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","slot_index":0,"links":[]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"UNETLoader","models":[{"name":"wan2.1_i2v_480p_14B_fp16.safetensors","url":"https://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/resolve/main/split_files/diffusion_models/wan2.1_i2v_480p_14B_fp16.safetensors?download=true","directory":"diffusion_models"}]},"widgets_values":["WanVideo\\ComfyOrg\\wan2.1_i2v_480p_14B_fp8_e4m3fn.safetensors","fp8_e4m3fn"]},{"id":40,"type":"WanVideoModelLoader","pos":[2770,1510],"size":[450,254],"flags":{},"order":18,"mode":0,"inputs":[{"localized_name":"compile_args","name":"compile_args","shape":7,"type":"WANCOMPILEARGS","link":null},{"localized_name":"block_swap_args","name":"block_swap_args","shape":7,"type":"BLOCKSWAPARGS","link":null},{"localized_name":"lora","name":"lora","shape":7,"type":"WANVIDLORA","link":null},{"localized_name":"vram_management_args","name":"vram_management_args","shape":7,"type":"VRAM_MANAGEMENTARGS","link":null},{"localized_name":"vace_model","name":"vace_model","shape":7,"type":"VACEPATH","link":null},{"localized_name":"fantasytalking_model","name":"fantasytalking_model","shape":7,"type":"FANTASYTALKINGMODEL","link":null}],"outputs":[{"localized_name":"model","name":"model","type":"WANVIDEOMODEL","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoModelLoader"},"widgets_values":["WanVideo\\ComfyOrg\\wan2.1_i2v_480p_14B_fp8_e4m3fn.safetensors","bf16","disabled","offload_device","sageattn"]},{"id":42,"type":"MarkdownNote","pos":[770,80],"size":[450,380],"flags":{},"order":19,"mode":0,"inputs":[],"outputs":[],"title":"Speedup and Enhance methods","properties":{},"widgets_values":["Speed UP:  \n[Triton (Torch Compile)](https://github.com/woct0rdho/triton-windows)  \n~30% speed increase if you have Triton installed and enabled.  \n[SageAttention](https://github.com/thu-ml/SageAttention)  \nalmost double inference speed if you have Sageattn installed and enabled.   \n[TeaCache](https://github.com/ali-vilab/TeaCache)  \nTeaCache could be considered to be sort of an automated step skipper.  \nThe relative l1 threshold -value determines how aggressive this is, higher values are faster but quality suffers more. Very first steps should NEVER be skipped with this model or it kills the motion. When using the pre-calculated coefficients, the treshold value should be much higher than with the default coefficients.  \n[Patch Model Patch Order](https://www.reddit.com/r/StableDiffusion/comments/1gjl982/lora_torchcompile_is_now_possible_thanks_to/)  \nWith weight_patch_first, switching to a different LoRA is really fast, no need for full recompile.  \n\n[Triton and SageAttention Installation](https://old.reddit.com/r/StableDiffusion/comments/1h7hunp/how_to_run_hunyuanvideo_on_a_single_24gb_vram_card/)  \n[Triton:supported GPU](https://github.com/woct0rdho/triton-windows#1-gpu)  \n[Triton:fp8 is not supported on RTX 30xx and older GPUs](https://github.com/woct0rdho/triton-windows#fp8-is-not-supported-on-rtx-30xx-and-older-gpus)  \n\nEnhance:  \n[Skip Layer Guidance](https://www.reddit.com/r/StableDiffusion/comments/1jac3wm/dramatically_enhance_the_quality_of_wan_21_using/)  \n[CFG Zero Star](https://github.com/WeichenFan/CFG-Zero-star)  \n[Enhance A Video](https://oahzxl.github.io/Enhance_A_Video/)  \nEnhance-a-video can increase the fidelity of the results (also time), too high values lead to noisy results.  \n[Unet Temporal Attention Multiply](https://www.runcomfy.com/comfyui-nodes/ComfyUI/UNetTemporalAttentionMultiply)  \nuseful for tasks that require temporal coherence and consistency, such as video frame interpolation, temporal segmentation, and other time-series related applications.  \n[RIFLEx](https://github.com/thu-ml/RIFLEx)  \nExtent video."],"color":"#432","bgcolor":"#653"},{"id":46,"type":"Note","pos":[2410,620],"size":[470,88],"flags":{},"order":21,"mode":0,"inputs":[],"outputs":[],"title":"fp8_fast and fp16_fast precision","properties":{},"widgets_values":["fp8_fast seems to cause huge quality degradation\n\nfp_16_fast enables \"Full FP16 Accmumulation in FP16 GEMMs\" feature available in the very latest pytorch nightly, this is around 20% speed boost. "],"color":"#432","bgcolor":"#653"},{"id":47,"type":"Note","pos":[1010,500],"size":[210,90],"flags":{},"order":22,"mode":0,"inputs":[],"outputs":[],"title":"Resolution","properties":{},"widgets_values":["360p : 640x360\n480p : 832x480 (854x480)\n540p : 960x544 (960x540)\n720p : 1280x720\n1080p: 1920x1080"],"color":"#432","bgcolor":"#653"},{"id":50,"type":"Note","pos":[770,630],"size":[230,88],"flags":{},"order":24,"mode":0,"inputs":[],"outputs":[],"title":"First Last Frame img2vid","properties":{},"widgets_values":["1. WanAI Wan i2v\n2. WanAI Wan flf2v\n3. Alibaba pai Wan Fun Inpaint\n4. Alibaba vi lab VACE flf"],"color":"#432","bgcolor":"#653"},{"id":41,"type":"Note","pos":[310,80],"size":[450,250],"flags":{},"order":25,"mode":0,"inputs":[],"outputs":[],"title":"vram arguments","properties":{},"widgets_values":["VRAM>RAM: --highvram\n  By default models will be unloaded to RAM after being used. This option keeps them in GPU memory.\n\nRAM>VRAM: --normalvram (default) or --lowvram\n  Split the unet in parts to use less VRAM.\n  ComfyUI does not unload models from VRAM unless there is insufficient space to load another model, as it aims to maximize the reuse of already loaded models. Without this feature, even when slightly modifying the parameters of a workflow and rerunning it, there will be a cost of reloading into VRAM.\n  This feature can be disabled using the --disable-smart-memory option.\nWhen --disable-smart-memory is applied, all data in VRAM is unloaded to RAM upon the completion of the workflow (based on the --normalvram setting).\n  Choose --normalvram when --lowvram isn't enough VRAM.\n\n--cpu\n  To use the CPU for everything (slow).\n"],"color":"#432","bgcolor":"#653"},{"id":33,"type":"TorchCompileModelWanVideo","pos":[-100,820],"size":[312.3999938964844,180],"flags":{},"order":26,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","slot_index":0,"links":[]}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"a5bd3c86c8ed6b83c55c2d0e7a59515b15a0137f","Node name for S&R":"TorchCompileModelWanVideo"},"widgets_values":["inductor",false,"default",false,64,false]},{"id":34,"type":"WanVideoTorchCompileSettings","pos":[-100,1170],"size":[310,202],"flags":{},"order":27,"mode":0,"inputs":[],"outputs":[{"localized_name":"torch_compile_args","name":"torch_compile_args","type":"WANCOMPILEARGS","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoTorchCompileSettings"},"widgets_values":["inductor",false,"default",false,64,true,128],"color":"#233","bgcolor":"#355"},{"id":43,"type":"UNetTemporalAttentionMultiply","pos":[-100,1470],"size":[310,130],"flags":{},"order":28,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":null}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"UNetTemporalAttentionMultiply"},"widgets_values":[1,1,1,1]},{"id":26,"type":"WanVideoTeaCache","pos":[240,1030],"size":[315,178],"flags":{},"order":29,"mode":0,"inputs":[],"outputs":[{"localized_name":"teacache_args","name":"teacache_args","type":"TEACACHEARGS","links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoTeaCache"},"widgets_values":[0.25,1,-1,"offload_device","true","e"],"color":"#233","bgcolor":"#355"},{"id":35,"type":"WanVideoTeaCacheKJ","pos":[240,820],"size":[310,154],"flags":{},"order":30,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"model","name":"model","type":"MODEL","slot_index":0,"links":[]}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"68db110554d5f1d9bef8d027a111a49fd7f85e1b","Node name for S&R":"WanVideoTeaCacheKJ"},"widgets_values":[0.25000000000000006,0.1,1,"offload_device","14B"]},{"id":53,"type":"SkipLayerGuidanceWanVideo","pos":[590,820],"size":[290,110],"flags":{},"order":31,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":[]}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"8ecf5cd05e0a1012087b0da90eea9a13674668db","Node name for S&R":"SkipLayerGuidanceWanVideo"},"widgets_values":["10",0.2,1]},{"id":20,"type":"WanVideoSLG","pos":[590,1390],"size":[290,106],"flags":{},"order":32,"mode":0,"inputs":[],"outputs":[{"localized_name":"slg_args","name":"slg_args","type":"SLGARGS","links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"cc8450b1a7f57d5a8ab25ba3dd040847056a95f4","Node name for S&R":"WanVideoSLG"},"widgets_values":["10",0.20000000000000004,1],"color":"#233","bgcolor":"#355"},{"id":52,"type":"WanVideoEnhanceAVideoKJ","pos":[920,820],"size":[300,80],"flags":{},"order":33,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null},{"localized_name":"latent","name":"latent","type":"LATENT","link":null}],"outputs":[{"localized_name":"model","name":"model","type":"MODEL","links":[]}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"8ecf5cd05e0a1012087b0da90eea9a13674668db","Node name for S&R":"WanVideoEnhanceAVideoKJ"},"widgets_values":[0.2]},{"id":22,"type":"WanVideoEnhanceAVideo","pos":[920,960],"size":[300,106],"flags":{},"order":34,"mode":0,"inputs":[],"outputs":[{"localized_name":"feta_args","name":"feta_args","type":"FETAARGS","links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoEnhanceAVideo"},"widgets_values":[2,0,1],"color":"#233","bgcolor":"#355"},{"id":21,"type":"CFGZeroStar","pos":[920,1170],"size":[300,26],"flags":{},"order":35,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"patched_model","name":"patched_model","type":"MODEL","links":[]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.29","Node name for S&R":"CFGZeroStar"},"widgets_values":[]},{"id":28,"type":"WanVideoExperimentalArgs","pos":[920,1260],"size":[304,226],"flags":{},"order":36,"mode":0,"inputs":[],"outputs":[{"localized_name":"exp_args","name":"exp_args","type":"EXPERIMENTALARGS","links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoExperimentalArgs"},"widgets_values":["",true,false,0,false,1,1.25,20],"color":"#233","bgcolor":"#355"},{"id":51,"type":"MarkdownNote","pos":[120,1690],"size":[360,510],"flags":{},"order":37,"mode":0,"inputs":[],"outputs":[],"title":"Running Time Comparison (txt2Vid)","properties":{},"widgets_values":["HDD & 64G RAM & 3090ti 24G VRAM  \n81 frames at 480x480 with 25 steps  \nSageAtt+TeaCache+SLG+EnhanceAVid  \nwan2.1_t2v_14B_fp8_e4m3fn.safetensors (ComfyOrg)  \n19 blocks swap for Wrapper  \n\n| 1st Run  | Native | Wrapper |\n|----------|--------|---------|\n| Loading  | 935s?  | 750s    |\n| Sampling | 435s   | 380s    |\n| Decoding | 10s    | 20s     |\n| Total    | 1380s  | 1150s   |\n\n| 2nd Run  | Native | Wrapper |\n|----------|--------|---------|\n| Loading  | 0s     | 5s      |\n| Sampling | 435s   | 380s    |\n| Decoding | 5s     | 10s     |\n| Total    | 440s   | 395s    |\n\n (sdpa attention in Wrapper workflow needs to reload the diffusion model)  \n| Speedup(without Triton)          | Native | Wrapper    |\n|----------------------------------|--------|------------|\n| SageAtt+TeaCache+SLG+EnhanceAVid | 440s   | 395s       |\n| SageAtt+TeaCache+SLG             | 300s   | 380s       |\n| SageAtt+TeaCache                 | 315s   | 395s       |\n| SageAtt                          | 520s   | 590s       |\n| -                                | 745s   | 835s(sdpa) |"],"color":"#432","bgcolor":"#653"},{"id":11,"type":"CLIPVisionLoader","pos":[1840,1130],"size":[400,58],"flags":{},"order":38,"mode":0,"inputs":[],"outputs":[{"localized_name":"CLIP_VISION","name":"CLIP_VISION","type":"CLIP_VISION","links":[]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.26","Node name for S&R":"CLIPVisionLoader"},"widgets_values":["WanVideo\\clip_vision_h.safetensors"]},{"id":45,"type":"LoadWanVideoClipTextEncoder","pos":[1840,1240],"size":[400,106],"flags":{},"order":39,"mode":4,"inputs":[],"outputs":[{"localized_name":"wan_clip_vision","name":"wan_clip_vision","type":"CLIP_VISION","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"LoadWanVideoClipTextEncoder"},"widgets_values":["WanVideo\\Kijai\\open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors","bf16","offload_device"]},{"id":37,"type":"WanVideoTextEncode","pos":[2770,830],"size":[450,230],"flags":{},"order":49,"mode":4,"inputs":[{"localized_name":"t5","name":"t5","type":"WANTEXTENCODER","link":9},{"localized_name":"model_to_offload","name":"model_to_offload","shape":7,"type":"WANVIDEOMODEL","link":null}],"outputs":[{"localized_name":"text_embeds","name":"text_embeds","type":"WANVIDEOTEXTEMBEDS","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoTextEncode"},"widgets_values":["a monkey robot is smiling","色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走",true]},{"id":15,"type":"WanVideoTextEmbedBridge","pos":[2970,1140],"size":[250,46],"flags":{},"order":53,"mode":0,"inputs":[{"localized_name":"positive","name":"positive","type":"CONDITIONING","link":6},{"localized_name":"negative","name":"negative","type":"CONDITIONING","link":7}],"outputs":[{"localized_name":"text_embeds","name":"text_embeds","type":"WANVIDEOTEXTEMBEDS","links":null}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"18aa47cc74534241835d2682bc5b51293082529c","Node name for S&R":"WanVideoTextEmbedBridge"},"widgets_values":[]},{"id":3,"type":"WanVideoTorchCompileSettings","pos":[1930,100],"size":[430,202],"flags":{},"order":40,"mode":0,"inputs":[],"outputs":[{"localized_name":"torch_compile_args","name":"torch_compile_args","type":"WANCOMPILEARGS","slot_index":0,"links":[11]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoTorchCompileSettings"},"widgets_values":["inductor",false,"default",false,64,true,128],"color":"#223","bgcolor":"#335"},{"id":36,"type":"Note","pos":[1340,50],"size":[320,660],"flags":{},"order":41,"mode":0,"inputs":[],"outputs":[],"title":"VRAM settings","properties":{},"widgets_values":["- >=12G VRAM, t2v 1.3B f32 model, f32 precision,\n  disabled quantization, main device\n  \n- 8G VRAM, t2v 1.3B f32 model, f32 precision,\n  disabled quantization, offload device\n  recomemdded blocks to swap: 10-12\n  \n  10 (might slightly exceed VRAM)\n  Transformer blocks on cpu: 1771.57MB\n  Transformer blocks on cuda:0: 3543.14MB\n  Total memory used by transformer blocks: 5314.72MB\n  Max allocated memory: max_memory=5.708 GB\n  Max reserved memory: max_reserved=6.219 GB\n  \n  11 (might just use up)\n  Transformer blocks on cpu: 1948.73MB\n  Transformer blocks on cuda:0: 3365.99MB\n  Total memory used by transformer blocks: 5314.72MB\n  Max allocated memory: max_memory=5.535 GB\n  Max reserved memory: max_reserved=6.062 GB\n\n  12 (remians extra VRAM)\n  Transformer blocks on cpu: 2125.89MB\n  Transformer blocks on cuda:0: 3188.83MB\n  Total memory used by transformer blocks: 5314.72MB\n  Max allocated memory: max_memory=5.362 GB\n  Max reserved memory: max_reserved=5.906 GB\n\n- 24G VRAM, i2v 14B f8 model, bf16 precision,\n  disabled quantization, offload device\n  recomemdded blocks to swap: 18-20\n  \n  18 (might slightly exceed VRAM)\n  Transformer blocks on cpu: 13865.75MB\n  Transformer blocks on cuda:0: 16947.03MB\n  Total memory used by transformer blocks: 30812.77MB\n  Max allocated memory: max_memory=21.781 GB\n  Max reserved memory: max_reserved=22.344 GB\n  \n  19 (might just use up)\n  Transformer blocks on cpu: 14636.07MB\n  Transformer blocks on cuda:0: 16176.71MB\n  Total memory used by transformer blocks: 30812.77MB\n  Max allocated memory: max_memory=21.028 GB\n  Max reserved memory: max_reserved=21.531 GB\n\n  20 (remians extra VRAM)\n  Transformer blocks on cpu: 15406.39MB\n  Transformer blocks on cuda:0: 15406.39MB\n  Total memory used by transformer blocks: 30812.77MB\n  Max allocated memory: max_memory=20.276 GB\n  Max reserved memory: max_reserved=20.844 GB"],"color":"#432","bgcolor":"#653"},{"id":29,"type":"Note","pos":[2410,70],"size":[470,190],"flags":{},"order":42,"mode":0,"inputs":[],"outputs":[],"title":"Diffusion Model Loader","properties":{},"widgets_values":["Quantization converts the diffusion model on the load which will reduce the VRAM and loading time even more. \n\nDuring sampling the weights are cast to base_precision when doing the actual calculations.\n\nmain_device: load transformer parameters to cuda (much quicker)\noffload_device: load transfomer paramters to cpu\n\nIn most cases: main_device for 1.3B fp32 model, offload_device for 14B fp8 model.\n\nOnly real reason to use main_device would be on cloud GPUs with more VRAM than RAM where you can do that to avoid swapping the models between GPU/CPU."],"color":"#432","bgcolor":"#653"},{"id":16,"type":"WanVideoTextEncode","pos":[2910,300],"size":[310,250],"flags":{},"order":43,"mode":0,"inputs":[{"localized_name":"t5","name":"t5","type":"WANTEXTENCODER","link":null},{"localized_name":"model_to_offload","name":"model_to_offload","shape":7,"type":"WANVIDEOMODEL","link":null}],"outputs":[{"localized_name":"text_embeds","name":"text_embeds","type":"WANVIDEOTEXTEMBEDS","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoTextEncode"},"widgets_values":["a monkey robot is smiling","色调艳丽，过曝，静态，细节模糊不清，字幕，风格，作品，画作，画面，静止，整体发灰，最差质量，低质量，JPEG压缩残留，丑陋的，残缺的，多余的手指，画得不好的手部，画得不好的脸部，畸形的，毁容的，形态畸形的肢体，手指融合，静止不动的画面，杂乱的背景，三条腿，背景人很多，倒着走",true],"color":"#332922","bgcolor":"#593930"},{"id":9,"type":"WanVideoModelLoader","pos":[2410,320],"size":[470,254],"flags":{},"order":52,"mode":0,"inputs":[{"localized_name":"compile_args","name":"compile_args","shape":7,"type":"WANCOMPILEARGS","link":11},{"localized_name":"block_swap_args","name":"block_swap_args","shape":7,"type":"BLOCKSWAPARGS","link":3},{"localized_name":"lora","name":"lora","shape":7,"type":"WANVIDLORA","link":null},{"localized_name":"vram_management_args","name":"vram_management_args","shape":7,"type":"VRAM_MANAGEMENTARGS","link":null},{"localized_name":"vace_model","name":"vace_model","shape":7,"type":"VACEPATH","link":null},{"localized_name":"fantasytalking_model","name":"fantasytalking_model","shape":7,"type":"FANTASYTALKINGMODEL","link":null}],"outputs":[{"localized_name":"model","name":"model","type":"WANVIDEOMODEL","slot_index":0,"links":[]}],"properties":{"cnr_id":"ComfyUI-WanVideoWrapper","ver":"d9b1f4d1a5aea91d101ae97a54714a5861af3f50","Node name for S&R":"WanVideoModelLoader"},"widgets_values":["WanVideo\\Wan2.1-t2v_1.3B.safetensors","fp32","disabled","offload_device","sageattn"],"color":"#223","bgcolor":"#335"},{"id":23,"type":"PatchModelPatcherOrder","pos":[250,1380],"size":[310,82],"flags":{},"order":44,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":[]}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"8ecf5cd05e0a1012087b0da90eea9a13674668db","Node name for S&R":"PatchModelPatcherOrder"},"widgets_values":["weight_patch_first","auto"]},{"id":27,"type":"PathchSageAttentionKJ","pos":[250,1270],"size":[310,58],"flags":{},"order":45,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","slot_index":0,"links":[]}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"9a15e22f5e9416c0968ce3de33923f8f601257dd","Node name for S&R":"PathchSageAttentionKJ"},"widgets_values":["auto"]},{"id":55,"type":"ApplyRifleXRoPE_WanVideo","pos":[250,1520],"size":[315,78],"flags":{},"order":46,"mode":0,"inputs":[{"localized_name":"model","name":"model","type":"MODEL","link":null},{"localized_name":"latent","name":"latent","type":"LATENT","link":null}],"outputs":[{"localized_name":"MODEL","name":"MODEL","type":"MODEL","links":null}],"properties":{"cnr_id":"comfyui-kjnodes","ver":"b7e5b6f1e2b7c79b3f1e4b4bfe5e1687715803ab","Node name for S&R":"ApplyRifleXRoPE_WanVideo"},"widgets_values":[6]},{"id":48,"type":"MarkdownNote","pos":[-100,1690],"size":[210,260],"flags":{},"order":47,"mode":0,"inputs":[],"outputs":[],"properties":{},"widgets_values":["Recommend native workflow:  \n1. t2v | i2v lora  \n2. Native Video Inpaint  \n3. Native VACE Video Repaint\n4. Not using features below:  \n- [Enhanced A Video](https://oahzxl.github.io/Enhance_A_Video/)\n- [Loop](https://github.com/YisuiTT/Mobius/)\n- Long context\n- [RIFLEx](https://github.com/thu-ml/RIFLEx)\n- [ReCamMaster](https://github.com/KwaiVGI/ReCamMaster)\n- [Fantasy Talking](https://github.com/Fantasy-AMAP/fantasy-talking)\n- [VACE](https://ali-vilab.github.io/VACE-Page/) other than Repaint\n- [Phantom](https://github.com/Phantom-video/Phantom)\n- Skyreel [A2](https://github.com/SkyworkAI/SkyReels-A2) [V2](https://github.com/SkyworkAI/SkyReels-V2)\n- [Flow Edit](https://github.com/fallenshock/FlowEdit)\n- [Unianimate](https://github.com/ali-vilab/UniAnimate)\n- [FreSca](https://github.com/WikiChao/FreSca)"],"color":"#432","bgcolor":"#653"},{"id":10,"type":"Note","pos":[310,370],"size":[450,300],"flags":{"collapsed":false},"order":48,"mode":0,"inputs":[],"outputs":[],"title":"Quantization","properties":{},"widgets_values":["Quality rank (highest to lowest):\n  fp32 > fp16 > bf16 > fp8_scaled > fp8_e4m3 | fp8_e5m2\n\n  fp vs. bf (https://medium.com/@furkangozukara/what-is-the-difference-between-fp16-and-bf16-here-a-good-explanation-for-you-d75ac7ec30fa)\n\nFP = Floating Point. Any signed floating point number is stored as 3 parts:\n  Sign bit, Mantissa, Exponent\n  number = sign * mantissa * 2 ^ exponent\n\nE5M2 means that 2 bits represent mantissa and 5 bits represent exponent.\nE4M3 means that 3 bits represent mantissa and 4 bits represent exponent.\n\nE5M2 can represent wider range of numbers than E4M3 at cost of lower precision of the numbers. But the amount of different numbers that can be represented are the same: 256 distinct values. So if we need more precision around 0 then we use E4M3 and if we need more precision closer to min/max values then we use E5M2.\n\nSo actually the best way to choose what format to use would be to analyse distribution of weight values in the model. And if they tend to be closer to zero we use E4M3 or E5M2 otherwise."],"color":"#432","bgcolor":"#653"},{"id":44,"type":"Note","pos":[1330,790],"size":[470,550],"flags":{},"order":20,"mode":0,"inputs":[],"outputs":[],"title":"Model","properties":{},"widgets_values":["Models:\nhttps://huggingface.co/Wan-AI\nhttps://huggingface.co/Comfy-Org/Wan_2.1_ComfyUI_repackaged/tree/main/split_files\nhttps://huggingface.co/Kijai/WanVideo_comfy/tree/main\n\n1. VAE:\n   different loader share model, but cannot replace each other\n   ① wan_2.1_VAE.safetensors (ComfyOrg)\n   ② Wan2_1_VAE_fp32.safetensors (Kijai) (recomended)\n     Wan2_1_VAE_bf16.safetensors (Kijai)\n\n2. Clip Vision:\n   different loader doesn't share model, but can replace each other\n   ① clip_vision_h.safetensors (ComfyOrg) (recomended)\n   ② open-clip-xlm-roberta-large-vit-huge-14_visual_fp32.safetensors (Kijai)\n     open-clip-xlm-roberta-large-vit-huge-14_visual_fp16.safetensors (Kijai)\n\n3. Clip(Text Encoder):\n   different loader doesn't share model, and cannot replace each other\n   You can use WanVideo TextEmbed Bridge Node to integrate the native Text Encoder process in the Wrapper workflow.\n   ① umt5_xxl_fp16.safetensors (ComfyOrg)\n     umt5_xxl_fp8_e4m3fn_scaled.safetensors (ComfyOrg)\n   ② umt5-xxl-enc-bf16.safetensors (Kijai)\n     umt5-xxl-enc-fp8_e4m3fn.safetensors (Kijai)\n   \n4. Diffusion(variation):\n   different loader share model, but cannot replace each other\n   For my 64G RAM & 3090ti 24G VRAM:\n   Bypass Triton and choose f8 series from ComfyOrg | Kijai.\n   If you choose bf16 series from ComfyOrg, enable Triton, bypass TeaCacheKJ and SLGWanVideoKJ (incompatable issue) in Native workflow.\n\n1.3B Control Lora:\nhttps://huggingface.co/spacepxl/Wan2.1-control-loras/tree/main/1.3b/depth\nhttps://huggingface.co/spacepxl/Wan2.1-control-loras/tree/main/1.3b/tile\n\nFun Control:\nhttps://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-Control/blob/main\nhttps://huggingface.co/alibaba-pai/Wan2.1-Fun-14B-Control/tree/main\nFun Inpaint:\nhttps://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-InP/blob/main\nhttps://huggingface.co/alibaba-pai/Wan2.1-Fun-14B-InP/tree/main"],"color":"#432","bgcolor":"#653"},{"id":49,"type":"Note","pos":[1010,630],"size":[210,88],"flags":{},"order":23,"mode":0,"inputs":[],"outputs":[],"title":"Reference(subject)2vid","properties":{},"widgets_values":["1. Alibaba vi lab VACE\n2. Phantom-video Phantam\n3. SkyworkAI Skyreel A2"],"color":"#432","bgcolor":"#653"}],"links":[[1,38,0,1,0,"CLIP"],[3,30,0,9,1,"BLOCKSWAPARGS"],[5,38,0,14,0,"CLIP"],[6,14,0,15,0,"CONDITIONING"],[7,1,0,15,1,"CONDITIONING"],[9,17,0,37,0,"WANTEXTENCODER"],[11,3,0,9,0,"WANCOMPILEARGS"]],"groups":[{"id":1,"title":"Wan Video Wrapper Tips","bounding":[1330,-20,1900,743.5999755859375],"color":"#3f789e","font_size":24,"flags":{}},{"id":2,"title":"You might need to know...","bounding":[300,10,930,721.5999755859375],"color":"#3f789e","font_size":24,"flags":{}},{"id":3,"title":"VAE","bounding":[1830,760,420,275.6000061035156],"color":"#3f789e","font_size":24,"flags":{}},{"id":4,"title":"CLIP Vision","bounding":[1830,1060,420,431.6000061035156],"color":"#3f789e","font_size":24,"flags":{}},{"id":5,"title":"Text Encode","bounding":[2270,760,960,663.5999755859375],"color":"#3f789e","font_size":24,"flags":{}},{"id":6,"title":"Diffusion","bounding":[2270,1440,960,337.6000061035156],"color":"#3f789e","font_size":24,"flags":{}},{"id":7,"title":"Speedup and Enhance nodes","bounding":[-110,750,1340,860],"color":"#3f789e","font_size":24,"flags":{}},{"id":8,"title":"Running Time Comparison","bounding":[-110,1620,1340,593.5999755859375],"color":"#3f789e","font_size":24,"flags":{}}],"config":{},"extra":{"ds":{"scale":1.926773293051374,"offset":[-487.5448206727331,-374.613547991304]}},"version":0.4}