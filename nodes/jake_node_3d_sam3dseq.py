"""
SAM3D Mesh Sequence Generator Nodes
å¤„ç†è§†é¢‘ã€mhr_paramså’ŒNPZæ–‡ä»¶ï¼Œç”ŸæˆäºŒè¿›åˆ¶Meshåºåˆ— (.bin)
"""

import os
import sys
import time
import struct
import json
import tempfile
import torch
import torch.nn.functional as F
from einops import rearrange
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Any
import torch
import numpy as np
import cv2

# =============================================================================
# é…ç½®å¸¸é‡
# =============================================================================

DEFAULT_FPS = 30.0  # é»˜è®¤å¸§ç‡
BINARY_MAGIC = b"MESH"  # é­”æ•°æ ‡è¯†
BINARY_VERSION = 2  # ç‰ˆæœ¬å·

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
CURRENT_FILE_DIR = Path(__file__).parent.absolute()

# =============================================================================
# æ£€æŸ¥ SAM3D ä¾èµ–æ˜¯å¦å¯ç”¨
# =============================================================================

def check_sam3d_dependencies():
    """
    æ£€æŸ¥ SAM3D ä¾èµ–æ˜¯å¦å¯ç”¨
    è¿”å›: (bool, str) - (æ˜¯å¦å¯ç”¨, é”™è¯¯ä¿¡æ¯)
    """
    # å°è¯•å¤šç§å¯èƒ½çš„SAM3DèŠ‚ç‚¹è·¯å¾„
    possible_paths = [
        # 1. å°è¯•ä»å½“å‰æ–‡ä»¶å‘ä¸Šå›æº¯æŸ¥æ‰¾
        CURRENT_FILE_DIR.parent.parent.parent / "ComfyUI_Motion" / "custom_nodes" / "ComfyUI-SAM3DBody",
        CURRENT_FILE_DIR.parent.parent.parent.parent / "ComfyUI_Motion" / "ComfyUI" / "custom_nodes" / "ComfyUI-SAM3DBody",
        
        # 2. å°è¯•ComfyUIæ ¹ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        CURRENT_FILE_DIR.parent.parent.parent / "ComfyUI-SAM3DBody",
        
        # 3. å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
        os.environ.get("SAM3D_NODE_PATH", ""),
        
        # 4. ç»å¯¹è·¯å¾„å¤‡é€‰
        Path(r"I:\ComfyUI_Motion\ComfyUI\custom_nodes\ComfyUI-SAM3DBody"),
    ]
    
    sam3d_node_path = None
    for path_str in possible_paths:
        if not path_str:
            continue
            
        path = Path(path_str) if isinstance(path_str, str) else path_str
        if path.exists():
            sam3d_node_path = path
            print(f"[SAM3D Check] Found SAM3D node at: {sam3d_node_path}")
            break
    
    if sam3d_node_path is None:
        return False, "æœªæ‰¾åˆ°SAM3DèŠ‚ç‚¹è·¯å¾„ï¼Œè¯·ç¡®ä¿å·²å®‰è£…ComfyUI-SAM3DBodyèŠ‚ç‚¹"
    
    # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒè·¯å¾„
    sam3d_env_path = sam3d_node_path / "_env_sam3dbody"
    if not sam3d_env_path.exists():
        print(f"[SAM3D Check] Warning: SAM3Dè™šæ‹Ÿç¯å¢ƒè·¯å¾„ä¸å­˜åœ¨: {sam3d_env_path}")
        # è™šæ‹Ÿç¯å¢ƒä¸æ˜¯å¿…éœ€çš„ï¼Œå¯ä»¥ç»§ç»­
    
    # å°è¯•å¯¼å…¥ sam_3d_body
    try:
        # å°† SAM3D èŠ‚ç‚¹è·¯å¾„æ·»åŠ åˆ° sys.path
        if str(sam3d_node_path) not in sys.path:
            sys.path.insert(0, str(sam3d_node_path))
        
        # å°è¯•å¯¼å…¥
        from sam_3d_body import load_sam_3d_body, SAM3DBodyEstimator
        
        print(f"[SAM3D Check] SAM3Dä¾èµ–æ£€æŸ¥é€šè¿‡")
        return True, "SAM3Dä¾èµ–æ£€æŸ¥é€šè¿‡"
    except ImportError as e:
        return False, f"æ— æ³•å¯¼å…¥SAM3Dæ¨¡å—: {str(e)}"
    except Exception as e:
        return False, f"SAM3Dä¾èµ–æ£€æŸ¥å¤±è´¥: {str(e)}"

# =============================================================================
# äºŒè¿›åˆ¶æ ¼å¼å®šä¹‰
# =============================================================================

class MeshSequenceBinaryFormat:
    """
    Binary Mesh sequence format V2
    
    Header structure (28 bytes):
    - magic: b"MESH" (4 bytes)
    - version: uint32 (4 bytes)  # Format version
    - num_frames: uint32 (4 bytes)
    - num_verts: uint32 (4 bytes)
    - num_faces: uint32 (4 bytes)
    - fps: float32 (4 bytes)
    - flags: uint32 (4 bytes)     # Flags
    - metadata_size: uint32 (4 bytes)  # Metadata size (bytes)
    
    Data section:
    - Vertex sequence: num_frames * num_verts * 3 * float32
    - Face data: num_faces * 3 * uint32
    - Metadata: metadata_size bytes of UTF-8 JSON string
    """
    
    @staticmethod
    def save_smpl_compatible(vertices_sequence: np.ndarray, faces: np.ndarray,
                             output_path: Path, fps: float = DEFAULT_FPS,
                             coordinate_transform: str = "rotate_z_180") -> Dict:
        """
        ä¿å­˜ä¸º SMPL å…¼å®¹æ ¼å¼ï¼ˆç”¨äº CompareSMPLtoBVH æŸ¥çœ‹å™¨ï¼‰
        
        å¤´éƒ¨ç»“æ„ (20å­—èŠ‚):
        - magic: b"SMPL" (4å­—èŠ‚)
        - num_frames: uint32 (4å­—èŠ‚)
        - num_verts: uint32 (4å­—èŠ‚)
        - num_faces: uint32 (4å­—èŠ‚)
        - fps: float32 (4å­—èŠ‚)
        
        æ•°æ®éƒ¨åˆ†:
        - é¡¶ç‚¹åºåˆ—: num_frames * num_verts * 3 * float32
        - é¢æ•°æ®: num_faces * 3 * uint32
        """
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        num_frames = vertices_sequence.shape[0]
        num_verts = vertices_sequence.shape[1]
        num_faces = faces.shape[0]
        
        print(f"[MeshSequence] Saving SMPL compatible sequence: {num_frames}frames, {num_verts}vertices, {num_faces}faces, {fps}FPS")
        
        # åº”ç”¨åæ ‡å˜æ¢
        if coordinate_transform != "none":
            vertices_sequence = apply_coordinate_transform(vertices_sequence, coordinate_transform)
        
        with open(output_path, 'wb') as f:
            # å†™å…¥å¤´éƒ¨ - SMPLæ ¼å¼
            magic = b"SMPL"
            f.write(magic)                                  # 4 bytes
            f.write(struct.pack('I', num_frames))           # 4 bytes
            f.write(struct.pack('I', num_verts))            # 4 bytes
            f.write(struct.pack('I', num_faces))            # 4 bytes
            f.write(struct.pack('f', fps))                  # 4 bytes
            
            # å†™å…¥é¡¶ç‚¹åºåˆ— (float32)
            # ç¡®ä¿é¡¶ç‚¹æ•°æ®æ˜¯Cè¿ç»­çš„
            vertices_flat = np.ascontiguousarray(vertices_sequence, dtype=np.float32).reshape(-1)
            f.write(vertices_flat.tobytes())
            
            # å†™å…¥é¢æ•°æ® (uint32)
            # ç¡®ä¿é¢æ•°æ®æ˜¯Cè¿ç»­çš„
            faces_flat = np.ascontiguousarray(faces, dtype=np.uint32).reshape(-1)
            f.write(faces_flat.tobytes())
        
        file_size = output_path.stat().st_size
        print(f"[MeshSequence] SMPL compatible file saved: {output_path} ({file_size / 1024 / 1024:.2f} MB)")
        
        return {
            'path': str(output_path),
            'num_frames': num_frames,
            'num_verts': num_verts,
            'num_faces': num_faces,
            'fps': fps,
            'coordinate_transform': coordinate_transform,
            'file_size_mb': file_size / 1024 / 1024
        }

# =============================================================================
# å…±äº«å‡½æ•°
# =============================================================================

# æ¨¡å—çº§ç¼“å­˜ï¼Œå¤ç”¨ SAM3DBodyProcess ä¸­çš„æ¨¡å‹
_MODEL_CACHE_PROCESS = {}

def _load_sam3d_model_process(model_config: dict):
    """
    åŠ è½½ SAM 3D Body æ¨¡å‹ï¼ˆä¸ process.py ä¸­çš„å‡½æ•°ç›¸åŒï¼‰
    """
    cache_key = model_config["ckpt_path"]

    if cache_key in _MODEL_CACHE_PROCESS:
        return _MODEL_CACHE_PROCESS[cache_key]

    # æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
    available, error_msg = check_sam3d_dependencies()
    if not available:
        raise ImportError(f"SAM3Dä¾èµ–ä¸å¯ç”¨: {error_msg}")

    # å¯¼å…¥ä¾èµ–
    from sam_3d_body import load_sam_3d_body

    ckpt_path = model_config["ckpt_path"]
    device = model_config["device"]
    mhr_path = model_config.get("mhr_path", "")

    print(f"[MeshSequence] Loading model: {ckpt_path}")
    sam_3d_model, model_cfg, _ = load_sam_3d_body(
        checkpoint_path=ckpt_path,
        device=device,
        mhr_path=mhr_path,
    )

    print(f"[MeshSequence] Model loaded, device: {device}")

    # ç¼“å­˜ç»“æœ
    result = {
        "model": sam_3d_model,
        "model_cfg": model_cfg,
        "device": device,
        "mhr_path": mhr_path,
    }
    _MODEL_CACHE_PROCESS[cache_key] = result

    return result

def apply_coordinate_transform(vertices_sequence: np.ndarray, transform_type: str = "rotate_z_180") -> np.ndarray:
    """
    å¯¹é¡¶ç‚¹åºåˆ—åº”ç”¨åæ ‡å˜æ¢
    
    å‚æ•°:
        vertices_sequence: (num_frames, num_verts, 3) çš„é¡¶ç‚¹åºåˆ—
        transform_type: å˜æ¢ç±»å‹
            - "rotate_z_180": ç»•Zè½´æ—‹è½¬180åº¦ (X,Yå–å)
            - "rotate_y_180": ç»•Yè½´æ—‹è½¬180åº¦ (X,Zå–å)
            - "rotate_x_180": ç»•Xè½´æ—‹è½¬180åº¦ (Y,Zå–å)
            - "rotate_z_90": ç»•Zè½´æ—‹è½¬90åº¦
            - "none": ä¸åº”ç”¨å˜æ¢
    
    è¿”å›:
        å˜æ¢åçš„é¡¶ç‚¹åºåˆ—
    """
    if transform_type == "none" or vertices_sequence is None:
        return vertices_sequence
    
    num_frames, num_verts, _ = vertices_sequence.shape
    transformed_sequence = vertices_sequence.copy()
    
    if transform_type == "rotate_z_180":
        # ç»•Zè½´æ—‹è½¬180åº¦: (x, y, z) -> (-x, -y, z)
        print(f"[CoordinateTransform] Rotate 180 degrees around Z axis: {num_frames}frames, {num_verts}vertices")
        transformed_sequence[:, :, 0] = -vertices_sequence[:, :, 0]  # Xå–å
        transformed_sequence[:, :, 1] = -vertices_sequence[:, :, 1]  # Yå–å
        # Zä¿æŒä¸å˜
    elif transform_type == "rotate_y_180":
        # ç»•Yè½´æ—‹è½¬180åº¦: (x, y, z) -> (-x, y, -z)
        print(f"[CoordinateTransform] Rotate 180 degrees around Y axis: {num_frames}frames, {num_verts}vertices")
        transformed_sequence[:, :, 0] = -vertices_sequence[:, :, 0]  # Xå–å
        transformed_sequence[:, :, 2] = -vertices_sequence[:, :, 2]  # Zå–å
        # Yä¿æŒä¸å˜
    elif transform_type == "rotate_x_180":
        # ç»•Xè½´æ—‹è½¬180åº¦: (x, y, z) -> (x, -y, -z)
        print(f"[CoordinateTransform] Rotate 180 degrees around X axis: {num_frames}frames, {num_verts}vertices")
        transformed_sequence[:, :, 1] = -vertices_sequence[:, :, 1]  # Yå–å
        transformed_sequence[:, :, 2] = -vertices_sequence[:, :, 2]  # Zå–å
        # Xä¿æŒä¸å˜
    elif transform_type == "rotate_z_90":
        # ç»•Zè½´æ—‹è½¬90åº¦: (x, y, z) -> (-y, x, z)
        print(f"[CoordinateTransform] Rotate 90 degrees around Z axis: {num_frames}frames, {num_verts}vertices")
        x_original = vertices_sequence[:, :, 0].copy()
        y_original = vertices_sequence[:, :, 1].copy()
        transformed_sequence[:, :, 0] = -y_original  # X = -Y
        transformed_sequence[:, :, 1] = x_original   # Y = X
        # Zä¿æŒä¸å˜
    else:
        print(f"[CoordinateTransform] Unknown transformation type: {transform_type}, no transformation applied")
    
    return transformed_sequence

def _gaussian_kernel1d(sigma, order=0, radius=None):
    """ç”Ÿæˆ1Dé«˜æ–¯æ ¸"""
    if radius is None:
        radius = int(4 * sigma + 0.5)
    
    x = torch.arange(-radius, radius + 1, dtype=torch.float32)
    x = x / sigma
    
    kernel = torch.exp(-0.5 * x ** 2)
    kernel = kernel / kernel.sum()
    
    return kernel.numpy()

def gaussian_smooth_numpy(x_np, sigma=3, dim=0):
    """
    NumPyç‰ˆæœ¬çš„é«˜æ–¯å¹³æ»‘å‡½æ•°ï¼ŒåŸºäºé™„ä»¶ä»£ç å®ç°
    """
    # è½¬æ¢ä¸ºPyTorchå¼ é‡ä»¥ä¾¿ä½¿ç”¨ç›¸åŒçš„å·ç§¯é€»è¾‘
    if isinstance(x_np, np.ndarray):
        x_tensor = torch.from_numpy(x_np).float()
    else:
        x_tensor = x_np
    
    # ç”Ÿæˆé«˜æ–¯æ ¸
    kernel_smooth = _gaussian_kernel1d(sigma=sigma, order=0, radius=int(4 * sigma + 0.5))
    kernel_smooth = torch.from_numpy(kernel_smooth).float()[None, None]  # (1, 1, K)
    rad = kernel_smooth.size(-1) // 2
    
    # ç¡®ä¿å¼ é‡åœ¨CPUä¸Š
    x_tensor = x_tensor.cpu()
    kernel_smooth = kernel_smooth.cpu()
    
    # è·å–åŸå§‹å½¢çŠ¶å¹¶å‡†å¤‡å·ç§¯
    x = x_tensor.transpose(dim, -1)
    x_shape = x.shape[:-1]
    x = rearrange(x, "... f -> (...) 1 f")  # (NB, 1, f)
    
    # ä½¿ç”¨replicateæ¨¡å¼è¿›è¡Œå¡«å……
    x = F.pad(x[None], (rad, rad, 0, 0), mode="replicate")[0]
    
    # æ‰§è¡Œå·ç§¯
    x = F.conv1d(x, kernel_smooth)
    
    # æ¢å¤åŸå§‹å½¢çŠ¶
    x = x.squeeze(1).reshape(*x_shape, -1)  # (..., f)
    x = x.transpose(-1, dim)
    
    # è½¬æ¢å›NumPy
    if isinstance(x_np, np.ndarray):
        return x.numpy()
    else:
        return x

def moving_average_smooth_numpy(x_np, window_size=5, dim=0):
    """
    NumPyç‰ˆæœ¬çš„ç§»åŠ¨å¹³å‡å¹³æ»‘å‡½æ•°
    """
    # è½¬æ¢ä¸ºPyTorchå¼ é‡
    if isinstance(x_np, np.ndarray):
        x_tensor = torch.from_numpy(x_np).float()
    else:
        x_tensor = x_np
    
    # ç”Ÿæˆå¹³å‡æ ¸
    kernel_smooth = torch.ones(window_size).float() / window_size
    kernel_smooth = kernel_smooth[None, None]  # (1, 1, window_size)
    rad = kernel_smooth.size(-1) // 2
    
    # ç¡®ä¿å¼ é‡åœ¨CPUä¸Š
    x_tensor = x_tensor.cpu()
    kernel_smooth = kernel_smooth.cpu()
    
    # è·å–åŸå§‹å½¢çŠ¶å¹¶å‡†å¤‡å·ç§¯
    x = x_tensor.transpose(dim, -1)
    x_shape = x.shape[:-1]
    x = rearrange(x, "... f -> (...) 1 f")  # (NB, 1, f)
    
    # ä½¿ç”¨replicateæ¨¡å¼è¿›è¡Œå¡«å……
    x = F.pad(x[None], (rad, rad, 0, 0), mode="replicate")[0]
    
    # æ‰§è¡Œå·ç§¯
    x = F.conv1d(x, kernel_smooth)
    
    # æ¢å¤åŸå§‹å½¢çŠ¶
    x = x.squeeze(1).reshape(*x_shape, -1)  # (..., f)
    x = x.transpose(-1, dim)
    
    # è½¬æ¢å›NumPy
    if isinstance(x_np, np.ndarray):
        return x.numpy()
    else:
        return x


# =============================================================================
# è§†é¢‘å¤„ç†èŠ‚ç‚¹
# =============================================================================

class SAM3DMeshSequenceFromVideo_JK:
    """
    ä»è§†é¢‘æ–‡ä»¶ç”Ÿæˆ Mesh åºåˆ—ï¼Œä½¿ç”¨ä¸ SAM3DBodyProcess ç›¸åŒçš„è¾“å…¥æ ¼å¼
    
    æ³¨æ„: æ­¤èŠ‚ç‚¹éœ€è¦ SAM3DBody èŠ‚ç‚¹çš„ä¾èµ–
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        # æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
        available, error_msg = check_sam3d_dependencies()
        if not available:
            print(f"è­¦å‘Š: SAM3Dä¾èµ–ä¸å¯ç”¨ï¼ŒèŠ‚ç‚¹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ: {error_msg}")
        
        return {
            "required": {
                "model": ("SAM3D_MODEL", {
                    "tooltip": "SAM3D æ¨¡å‹é…ç½®"
                }),
                "image": ("IMAGE", {
                    "tooltip": "è§†é¢‘å¸§åºåˆ—ï¼ˆæ‰¹å¤„ç†çš„å›¾åƒï¼‰"
                }),
                "output_filename": ("STRING", {
                    "default": "mesh_sequence.bin",
                    "multiline": False,
                    "placeholder": "è¾“å‡ºæ–‡ä»¶å (ä¼šè‡ªåŠ¨æ·»åŠ æ—¶é—´æˆ³)",
                    "tooltip": "è¾“å‡ºäºŒè¿›åˆ¶æ–‡ä»¶åï¼Œä¼šä¿å­˜åœ¨ Adv3DViewer_JK_tmp ç›®å½•"
                }),
            },
            "optional": {
                "bbox_threshold": ("FLOAT", {
                    "default": 0.8,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.05,
                    "tooltip": "äººä½“æ£€æµ‹é˜ˆå€¼"
                }),
                "inference_type": (["full", "body", "hand"], {
                    "default": "full",
                    "tooltip": "æ¨ç†ç±»å‹"
                }),
                "mask": ("MASK", {
                    "tooltip": "å¯é€‰çš„åˆ†å‰²æ©ç åºåˆ—"
                }),
                "coordinate_transform": (["none", "rotate_z_180", "rotate_y_180", "rotate_x_180", "rotate_z_90"], {
                    "default": "rotate_z_180",
                    "tooltip": "åæ ‡å˜æ¢ç±»å‹ã€‚é€šå¸¸ä½¿ç”¨rotate_z_180ä¿®æ­£æœå‘é—®é¢˜"
                }),
                "smoothing_sigma": ("FLOAT", {
                    "default": 3.0,
                    "min": 0.5,
                    "max": 10.0,
                    "step": 0.5,
                    "tooltip": "é«˜æ–¯å¹³æ»‘æ ¸å®½åº¦ï¼ˆè¶Šé«˜è¶Šå¹³æ»‘ï¼‰"
                }),
                "smoothing_method": (["gaussian", "moving_average"], {
                    "default": "gaussian",
                    "tooltip": "å¹³æ»‘ç®—æ³•"
                }),
            }
        }
    
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("bin_file_path",)
    FUNCTION = "generate_from_video_frames"
    CATEGORY = "ğŸ‰ JK/ğŸ•’ 3D"
    OUTPUT_NODE = True
    
    def __init__(self):
        """åˆå§‹åŒ–è¾“å‡ºç›®å½•ï¼Œå‚è€ƒjake_node_3d_viewer.py"""
        # æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
        available, error_msg = check_sam3d_dependencies()
        if not available:
            print(f"è­¦å‘Š: SAM3Dä¾èµ–ä¸å¯ç”¨ï¼ŒèŠ‚ç‚¹å¯èƒ½æ— æ³•æ­£å¸¸å·¥ä½œ: {error_msg}")
        
        import folder_paths
        self.output_dir = folder_paths.get_output_directory()
        self.tmp_output_dir_name = "Adv3DViewer_JK_tmp"
        
        # åªåœ¨éœ€è¦æ—¶åˆ›å»ºç›®å½•
        tmp_output_dir = Path(self.output_dir) / self.tmp_output_dir_name
        tmp_output_dir.mkdir(parents=True, exist_ok=True)
        
        print(f"[SAM3DMeshSequence] Output directory: {tmp_output_dir}")
    
    def get_tmp_output_dir(self):
        """è·å–ä¸´æ—¶è¾“å‡ºç›®å½•çš„ Path å¯¹è±¡"""
        return Path(self.output_dir) / self.tmp_output_dir_name
    
    def clean_file_path(self, file_path: str) -> str:
        """æ¸…ç†æ–‡ä»¶è·¯å¾„ï¼Œå»é™¤å¯èƒ½çš„å¼•å·ï¼ˆå‚è€ƒjake_node_3d_viewer.pyï¼‰"""
        if not file_path:
            return ""
        
        # å»é™¤é¦–å°¾çš„å¼•å·ï¼ˆå•å¼•å·å’ŒåŒå¼•å·ï¼‰
        file_path = file_path.strip()
        if (file_path.startswith('"') and file_path.endswith('"')) or \
           (file_path.startswith("'") and file_path.endswith("'")):
            file_path = file_path[1:-1]
        
        return file_path.strip()
    
    def smooth_sequence(self, sequence: np.ndarray, sigma: float = 3.0, method: str = "gaussian") -> np.ndarray:
        """
        åº”ç”¨æ—¶é—´å¹³æ»‘åˆ°åºåˆ—ä¸Š
        """
        if sequence.shape[0] <= 1 or sigma <= 0:
            return sequence
        
        if method == "gaussian":
            smoothed = gaussian_smooth_numpy(sequence, sigma=sigma, dim=0)
        else:  # moving_average
            window_size = int(sigma * 2 + 1)
            smoothed = moving_average_smooth_numpy(sequence, window_size=window_size, dim=0)
        
        return smoothed
    
    def generate_from_video_frames(self, model, image, output_filename,
                                  bbox_threshold=0.8, inference_type="full", mask=None,
                                  coordinate_transform="rotate_z_180",
                                  smoothing_sigma=3.0, smoothing_method="gaussian"):
        """
        ä»å›¾åƒåºåˆ—ï¼ˆè§†é¢‘å¸§ï¼‰ç”Ÿæˆ Mesh åºåˆ—
        """
        
        import time
        start_time_total = time.time()
        
        # æ£€æŸ¥ä¾èµ–æ˜¯å¦å¯ç”¨
        available, error_msg = check_sam3d_dependencies()
        if not available:
            return (f"é”™è¯¯: SAM3Dä¾èµ–ä¸å¯ç”¨ - {error_msg}",)
        
        # 1. æ£€æŸ¥è¾“å…¥å›¾åƒ
        if image is None or len(image) == 0:
            return (f"é”™è¯¯: æ²¡æœ‰è¾“å…¥å›¾åƒ",)
        
        num_frames = len(image)
        print(f"[VideoFramesToMesh] Input image sequence: {num_frames}frames")
        print(f"[VideoFramesToMesh] Coordinate transformation: {coordinate_transform}")
        print(f"[VideoFramesToMesh] Temporal smoothing: enabled, method: {smoothing_method}, sigma: {smoothing_sigma}")
        
        # 2. åŠ è½½æ¨¡å‹
        model_start_time = time.time()
        
        device = model.get("device", "cuda")
        if not torch.cuda.is_available():
            device = "cpu"
        
        model_config = model.copy()
        model_config["device"] = device
        
        try:
            loaded = _load_sam3d_model_process(model_config)
        except ImportError as e:
            return (f"é”™è¯¯: æ— æ³•åŠ è½½SAM3Dæ¨¡å‹ - {str(e)}",)
        
        print(f"[VideoFramesToMesh] Model loaded, time: {time.time() - model_start_time:.2f}seconds")
        
        # 3. è·å–é¢æ•°æ®
        from sam_3d_body import SAM3DBodyEstimator
        
        estimator = SAM3DBodyEstimator(
            sam_3d_body_model=loaded["model"],
            model_cfg=loaded["model_cfg"],
            human_detector=None,
            human_segmentor=None,
            fov_estimator=None,
        )
        
        faces = estimator.faces
        if faces is None:
            try:
                if hasattr(loaded["model"], 'faces'):
                    faces = loaded["model"].faces
                elif hasattr(loaded["model_cfg"], 'faces'):
                    faces = loaded["model_cfg"].faces
            except:
                pass
        
        if faces is None:
            return (f"é”™è¯¯: æ— æ³•è·å–é¢æ•°æ®",)
        
        # 4. å‡†å¤‡è¾“å‡ºè·¯å¾„
        # æ¸…ç†æ–‡ä»¶å
        output_filename = self.clean_file_path(output_filename)
        
        # ç”Ÿæˆå”¯ä¸€çš„æ–‡ä»¶å
        timestamp = int(time.time() * 1000)
        
        # ç¡®ä¿æ–‡ä»¶åä»¥.binç»“å°¾
        if not output_filename.lower().endswith('.bin'):
            output_filename += '.bin'
        
        # æ·»åŠ æ—¶é—´æˆ³ä»¥ç¡®ä¿å”¯ä¸€æ€§
        base_name = Path(output_filename).stem
        extension = Path(output_filename).suffix
        unique_filename = f"{base_name}_{timestamp}{extension}"
        
        # ä½¿ç”¨ get_tmp_output_dir æ–¹æ³•è·å– Path å¯¹è±¡
        tmp_output_dir = self.get_tmp_output_dir()
        output_path = tmp_output_dir / unique_filename
        
        print(f"[VideoFramesToMesh] Output file: {output_path}")
        
        # 5. å¤„ç†å›¾åƒåºåˆ— - æ”¶é›†é¡¶ç‚¹ä¿¡æ¯
        vertices_sequence = []
        processed_frames = 0
        failed_frames = 0
        
        print(f"[VideoFramesToMesh] Start processing {num_frames} frames...")
        
        # ä¸´æ—¶ç›®å½•ç”¨äºä¿å­˜å¸§å›¾åƒ
        with tempfile.TemporaryDirectory() as temp_dir:
            temp_dir_path = Path(temp_dir)
            
            # é€å¸§å¤„ç†
            for frame_idx in range(num_frames):
                try:
                    # è½¬æ¢ ComfyUI å›¾åƒä¸º numpy
                    img_tensor = image[frame_idx]
                    if len(img_tensor.shape) == 4:  # [B, H, W, C]
                        img_np = img_tensor[0].cpu().numpy()
                    else:  # [H, W, C]
                        img_np = img_tensor.cpu().numpy()
                    
                    # è½¬æ¢ä¸º BGR å’Œ uint8
                    img_np = (img_np * 255).astype(np.uint8)
                    img_bgr = img_np[..., ::-1].copy()  # RGB -> BGR
                    
                    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    frame_path = temp_dir_path / f"frame_{frame_idx:06d}.jpg"
                    cv2.imwrite(str(frame_path), img_bgr)
                    
                    # å‡†å¤‡æ©ç ï¼ˆå¦‚æœæœ‰ï¼‰
                    mask_np = None
                    if mask is not None and len(mask) > frame_idx:
                        mask_tensor = mask[frame_idx]
                        if len(mask_tensor.shape) == 3:  # [B, H, W]
                            mask_np = mask_tensor[0].cpu().numpy()
                        else:  # [H, W]
                            mask_np = mask_tensor.cpu().numpy()
                    
                    # è®¡ç®—è¾¹ç•Œæ¡†ï¼ˆå¦‚æœæœ‰æ©ç ï¼‰
                    bboxes = None
                    if mask_np is not None:
                        rows = np.any(mask_np > 0.5, axis=1)
                        cols = np.any(mask_np > 0.5, axis=0)
                        
                        if rows.any() and cols.any():
                            rmin, rmax = np.where(rows)[0][[0, -1]]
                            cmin, cmax = np.where(cols)[0][[0, -1]]
                            bboxes = np.array([[cmin, rmin, cmax, rmax]], dtype=np.float32)
                    
                    # å¤„ç†å•å¸§å›¾åƒ
                    outputs = estimator.process_one_image(
                        str(frame_path),
                        bboxes=bboxes,
                        masks=mask_np,
                        bbox_thr=bbox_threshold,
                        use_mask=(mask_np is not None),
                        inference_type=inference_type,
                    )
                    
                    if not outputs or len(outputs) == 0:
                        print(f"[VideoFramesToMesh] Warning: Frame {frame_idx} no human detected")
                        failed_frames += 1
                        
                        # æ·»åŠ ç©ºç™½å¸§
                        num_verts = faces.shape[0]
                        blank_vertices = np.zeros((num_verts, 3))
                        vertices_sequence.append(blank_vertices)
                        
                        processed_frames += 1
                        continue
                    
                    # å–ç¬¬ä¸€ä¸ªæ£€æµ‹åˆ°çš„äººä½“
                    output = outputs[0]
                    
                    # æå–é¡¶ç‚¹
                    pred_vertices = output.get("pred_vertices")
                    if pred_vertices is None:
                        print(f"[VideoFramesToMesh] Warning: Frame {frame_idx} no vertex output, using blank frame")
                        num_verts = faces.shape[0]
                        blank_vertices = np.zeros((num_verts, 3))
                        vertices_sequence.append(blank_vertices)
                    else:
                        # è½¬æ¢ä¸º numpy æ•°ç»„
                        if torch.is_tensor(pred_vertices):
                            vertices = pred_vertices.detach().cpu().numpy()
                        else:
                            vertices = pred_vertices
                        
                        vertices_sequence.append(vertices)
                    
                    processed_frames += 1
                    
                except Exception as e:
                    print(f"[VideoFramesToMesh] Error: Processing frame {frame_idx} failed - {e}")
                    failed_frames += 1
                    
                    # æ·»åŠ ç©ºç™½å¸§
                    num_verts = faces.shape[0]
                    blank_vertices = np.zeros((num_verts, 3))
                    vertices_sequence.append(blank_vertices)
                    
                    processed_frames += 1
                
                # æ¯å¤„ç†10å¸§æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if (frame_idx + 1) % 10 == 0 or (frame_idx + 1) == num_frames:
                    elapsed = time.time() - start_time_total
                    fps_rate = processed_frames / elapsed if elapsed > 0 else 0
                    print(f"[VideoFramesToMesh] Progress: {frame_idx + 1}/{num_frames} frames, "
                          f"Success: {processed_frames - failed_frames}, Failed: {failed_frames}, "
                          f"Speed: {fps_rate:.1f} FPS")
        
        if processed_frames == 0:
            return (f"é”™è¯¯: æ²¡æœ‰æˆåŠŸå¤„ç†ä»»ä½•å¸§",)
        
        # 6. è½¬æ¢ä¸º numpy æ•°ç»„
        vertices_sequence_np = np.stack(vertices_sequence, axis=0)
        
        # 7. æ€»æ˜¯åº”ç”¨æ—¶é—´å¹³æ»‘ï¼ˆå¦‚æœæœ‰å¤šäº1å¸§ï¼‰
        if processed_frames > 1:
            print(f"[VideoFramesToMesh] Applying temporal smoothing (method: {smoothing_method}, sigma: {smoothing_sigma})")
            
            vertices_sequence_np = self.smooth_sequence(
                vertices_sequence_np, 
                sigma=smoothing_sigma, 
                method=smoothing_method
            )
            
            print(f"[VideoFramesToMesh] Temporal smoothing completed")
        
        # 8. åº”ç”¨åæ ‡å˜æ¢
        if coordinate_transform != "none":
            print(f"[CoordinateTransform] Applying coordinate transformation: {coordinate_transform}")
            
            # å˜æ¢é¡¶ç‚¹åºåˆ—
            vertices_sequence_np = apply_coordinate_transform(vertices_sequence_np, coordinate_transform)
        
        # 9. æ€»æ˜¯ä¿å­˜ä¸º SMPL å…¼å®¹æ ¼å¼
        MeshSequenceBinaryFormat.save_smpl_compatible(
            vertices_sequence=vertices_sequence_np,
            faces=faces,
            output_path=output_path,
            fps=DEFAULT_FPS,
            coordinate_transform="none"  # å·²ç»åœ¨å‰é¢åº”ç”¨äº†å˜æ¢
        )
        
        print(f"[VideoFramesToMesh] SMPL compatible format generation completed! Total time: {time.time() - start_time_total:.2f}seconds")
        print(f"[VideoFramesToMesh] Successfully processed: {processed_frames - failed_frames}frames, Failed: {failed_frames}frames")
        print(f"[VideoFramesToMesh] Coordinate transformation: {coordinate_transform}")
        print(f"[VideoFramesToMesh] Temporal smoothing: enabled ({smoothing_method}, sigma={smoothing_sigma})")
        print(f"[VideoFramesToMesh] Output file: {output_path}")
        
        # åªè¿”å›å®Œæ•´è·¯å¾„
        return (str(output_path),)
